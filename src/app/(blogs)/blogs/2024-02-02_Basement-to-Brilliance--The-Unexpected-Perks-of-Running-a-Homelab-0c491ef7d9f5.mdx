---
title: Basement to Brilliance  The Unexpected Perks of Running a Homelab
date: 2024-02-02
---


# Basement to Brilliance: The Unexpected Perks of Running a Homelab

“If you use a proprietary program or somebody else’s web server, you’re defenceless. You’re putty in the hands of whoever developed that…

> “If you use a proprietary program or somebody else’s web server, you’re defenceless. You’re putty in the hands of whoever developed that software.” — Richard Stallman

In the dimly lit confines of my house, I embarked on a journey from De-Googling my life to creating a homelab that would evolve into a brilliant tapestry of technology and learning. Hi, I’m [Rodney Osodo](https://rodneyosodo.com/), known as [@blackd0t](https://twitter.com/b1ackd0t) on Twitter, and I’m not just a software engineer; I’m the curator of my [homelab adventure](https://github.com/rodneyosodo/homelab/tree/v1.0.0). The walls of my homelab are adorned with servers and the hum of endless possibilities as I dive into the world of new technologies and host my projects. This digital playground, my homelab, has become the canvas for my exploration.

With goals ranging from liberating myself from the clutches of Google to creating a robust, highly available infrastructure for my projects, each checkbox became a stepping stone toward homelab brilliance. The allure of a scalable environment with no single point of failure beckoned me, pushing the boundaries of my understanding. Learning new technologies isn’t just a task; it is a thrilling adventure, and having fun is the north star guiding my every endeavour.

![](/blogs/medium/1____EygdM0PP__WjAqE3Nzueag.png)

Reaching the point where I can proudly declare, “I have a homelab,” feels like a significant milestone. It might not be the most expensive setup, but it’s mine — a carefully curated space where technology and creativity intertwine.

The heartbeat of my homelab is a Raspberry Pi (Heimdall), dutifully serving as a backup server running. Alongside it stands a mini PC (Odin), my trusted central server, orchestrating various services. Another mini PC, Hœnir, proudly takes on the role of my main workstation, where countless lines of code come to life. My laptop, Dellingr, transforms into a mobile workstation for those on-the-go moments, ensuring productivity knows no bounds. As my homelab continues to evolve, there’s a promise of more servers on the horizon, each waiting to join the ensemble. The journey has just begun, and the prospect of enhancing my homelab with additional servers and services makes the future brim with possibilities.

![](/blogs/medium/1__41x0kVc5F2Gal8Fjxzm__Sg.jpeg)

### **Heimdall**

\- 64-bit Raspberry Pi OS Lite (Debian 12 running kernel: 6.1)

\- Raspberry Pi 4 Model B

\- 4GB RAM

\- 64 GB SD Card

\- 1x 4TB HDD as data disk

This server is used exclusively as a backup server. I use it to back up my homelab machines and possibly my family’s machines. When selecting Heimdall’s hardware, reliability took precedence over sheer power. The Raspberry Pi 4, known for its affordability and stability, became the natural choice. Opting for the 4GB RAM version ensured the smooth operation of the 64-bit OS and the backup software, creating a balance between performance and cost-effectiveness. I chose a 64GB SD card for the OS, while a 4TB HDD is the data disk. The intention was not only to store backups but also to maintain multiple copies for added reliability.

However, the journey had its challenges. An unforeseen block size discrepancy between the Raspberry Pi (using 512 blocks) and the HDD (with a 4096 block size) led to an unfortunate compatibility issue. Here is the [issue](https://forums.raspberrypi.com/viewtopic.php?t=334314). Despite attempts to integrate the Proxmox Backup Server, both as the base OS or containerised, the hurdles persisted, prompting a reevaluation of the setup. Here is the [issue](https://forum.proxmox.com/threads/pbs-on-a-raspberry-pi.85051/).

In response to these challenges, I will transition Heimdall’s duties to an Intel N100 mini PC. This upgrade aims to overcome the compatibility issues and provide a seamless environment for backup operations.

![](/blogs/medium/1__0shIZnLvpGHGIu13ODKp__A.jpeg)

### **Odin**

\- Proxmox 8.1.4 (Debian 12 running kernel: 6.5.11–7-pve)

\- AMD Ryzen 7 4800H with Radeon Graphics (16) @ 1.4GHz — 2.9GHz

\- 32 GB DDR4–3200 Memory

\- 1x 1 TB NVMe SSD as boot disk

\- 1x 2 TB HDD as data disk

My primary server is hosted on this machine. I use it to run all of my virtualised and containerised services. At the moment, I have a VM called Bohr that runs all my services. I will add more VMs soon for testing and running Kubernetes.

I chose the AMD Ryzen 7 4800H with Radeon Graphics (16) @ 1.4GHz — 2.9GHz because it’s cheap and reliable. I picked the 32 GB DDR4–3200 Memory to have enough RAM to run the OS and the services. I will upgrade to 64 GB DDR4–3200 Memory as soon as my needs grow. I chose a 1 TB NVMe SSD as the boot disk. I picked a 2 TB HDD as a data disk because I wanted enough storage for the VMS. I will probably increase the number of VMs as my needs grow. I will add more storage as my needs grow.

![](/blogs/medium/1__seXGxxKI9QcAy93lFQFl3Q.jpeg)

This server is the most powerful in my homelab. It runs proxmox as the base OS. I have configured proxmox to use ZFS as the storage backend. It utilises the 2 TB HDD as the data disk. ZFS is pretty cool. It allows me to create snapshots of the data disk. I can use these snapshots to restore the data disk to a previous state. I have also configured scheduled backups of the VM. This happens every night at 2 AM.

![](/blogs/medium/1__Ah__R837zylLSxPMcKl4WVA.png)

Currently, I’m running all my services on a single VM. The services I’m running are:

*   **Portainer** is a lightweight management UI that allows you to easily manage your different Docker environments. It consists of a single container that can run on any Docker engine. Portainer allows you to manage all your Docker resources (containers, images, volumes, networks and more)

![](/blogs/medium/1__2bZ__QjRsPn8PWM7gaQvBtw.png)

*   **uptime-kuma** is a self-hosted monitoring service that you can use to keep track of the health of your applications, websites, and APIs. I have configured it to watch services with different types of health checks and set up email notifications for when there are problems.

![](/blogs/medium/1__bnAxBwuTFz5jz0BtNAkSOQ.png)

*   **Heimdall** is a way to easily organise all those links to your most used websites and web applications. Simplicity is the key to Heimdall.

![](/blogs/medium/1__9su4Eso77dpgMszuwdMUcg.png)

*   **Postgres** — is an open-source database with a strong reputation for its reliability, flexibility, and support of open technical standards. It is designed to handle a range of workloads, from single machines to data warehouses or Web services with many concurrent users.
*   **Nextcloud** is a self-hosted, open-source file-sharing and collaboration platform that allows users to store, access, and share their data from any device or location. Nextcloud was created as a fork of ownCloud. It serves as my replacement for Google Drive.

![](/blogs/medium/1__N__l7EmWObzYPAtmUK4W__gQ.png)

*   **Littlelink** is an open-source DIY Linktree alternative.
*   **NTP** is a communication protocol synchronising clocks across devices using TCP/IP communication. It synchronises the time on your local system to a centralised NTP server.
*   **cloudflared** is a tunnelling daemon that proxies any local webserver through the Cloudflare network. It secures traffic, hides your origin server IP address, and blocks malicious traffic.
*   **pihole** is a DNS sinkhole that protects your devices from unwanted content without installing client-side software. I use it to block ads and track network activity. It also serves as a DNS server with unbound as the upstream DNS server.

![](/blogs/medium/1__Qd1iE1IE__b3fyn2Mh4Rw3w.png)

*   **swagger-editor** — is a browser-based editor where you can write OpenAPI specs.
*   **immich** — is a photo album I use to store all my photos. I use it to store all my photos. Immich is divided into several services run as individual docker containers. It serves as my replacement for Google Photos.

![](/blogs/medium/1__2Pdr8S__fIy__V6a4ZaTfG6A.png)

*   **Redis** — is an open-source, in-memory data structure store used as a database, cache, and message broker. It stores data in memory and is often used as a cache.
*   **Vaultwarden** is an alternative implementation of the Bitwarden server API written in Rust. It is compatible with upstream Bitwarden clients. I use it to store my passwords and other sensitive information, replacing Google passwords.
*   **Opengist** is an open-source, self-hosted, web-based code snippet manager. I used it to store code snippets.
*   **speedtest-tracker** is a self-hosted, open source, lightweight, and easy-to-use speed test tracker. I use it to track my internet speed.

![](/blogs/medium/1__dmFK__1zikRB7Ntu4PIZfmA.png)

*   **dozzle** is a simple container log viewer for Docker. I use it to view logs of docker containers.

![](/blogs/medium/1__x84JUeU1wZy8yXs4g3AS2Q.png)

*   **endlessh** is an SSH tarpit that sends an endless, random SSH banner very slowly. It keeps SSH clients locked up for hours or even days. Instead of bothering a real server, the purpose is to put your SSH server on another port and let the script kiddies get stuck in this tarpit.

### **Conclusion**

In the grand scheme of my homelab evolution, I’m gearing up for a transformative leap to version 2.0. The impending upgrade involves adding new machines and expanding services, marking a significant architectural shift with the introduction of Kubernetes. The decision between k3s and k8s is yet to be finalised as I immerse myself in the intricacies of these powerful orchestration tools, navigating the vast landscape of containerised deployments.

Beyond the orchestration prowess of Kubernetes, version 2.0 heralds the dawn of Infrastructure as Code (IaC). Terraform will take the reins, orchestrating the provisioning of machines, while Ansible handles the configuration of services deftly. This dual approach ensures a streamlined, automated, and scalable infrastructure, paving the way for efficient management and future expansion.

The endgame for this ambitious homelab upgrade is nothing short of a highly available marvel. By eliminating single points of failure, both in hardware and software, I aim to fortify the foundation of my homelab. Every system and byte of data will be diligently backed up and protected, forming an impenetrable fortress of resilience. I will implement load balancing and failover mechanisms to guarantee the highest service availability, creating a homelab that meets and exceeds my expectations.

The roadmap includes continuous monitoring to ensure peak performance and the implementation of a reliable failover strategy for all services. As the curtains rise on version 2.0, I anticipate a landscape reshaped by the evolving workloads, promising a dynamic and ever-improving homelab environment in the coming weeks and years. The journey ahead is discovery, growth, and the relentless pursuit of homelab excellence.

> “If programmers deserve to be rewarded for creating innovative programs, by the same token they deserve to be punished if they restrict the use of these programs.” — Richard Stallman

You can visit my [GitHub page](https://github.com/rodneyosodo/homelab/tree/v1.0.0) for more information about my home lab. If you have any questions, feel free to contact me on [Twitter](https://twitter.com/b1ackd0t). I'm always happy to chat about homelabs and technology.

If you liked this article, click the👏 below multiple times so others will see it here on Medium.

Let’s be friends on [Twitter](https://twitter.com/b1ackd0t). Happy Hacking 😉


